* Big O

Most commonly encountered time complexities:

* Constant time: O(1). Execution time does not depend on the size of the input.

* Logarithmic time: O(log n). Execution time is proportional to the logarithm of the input size. 
In layman's terms this means that number of elements in the problem space gets significantly decreased 
(e. g. halved) on each iteration. Binary trees, heaps and binary search are common examples of this.

* Linear time: O(n). Execution time is proportional to the input size. Common example of this is any algorithm 
that iterates through given array exactly once.

O(mn) is usually considered to be linear as well. Common example of this is processing each element of array X for each element of array Y

* Linearithmic time: O(n log n). This is complexity of optimized sorting algorithms, such as heapsort, mergesort and quicksort. 

* Quadratic time: O(n-power(2)). Execution time is proportional to the square (n\*n) of the input size.

* Cubic time: O(n-power(3)). Execution time is proportional to the cube (n\*n\*n) of the input size.

* Exponential time: O(2-power(n)). Execution time is proportional to the exponentiation (2 power n) by the input size.

* Factorial time: O(n!). Execution time is proportional to the factorial (n! = n × (n−1)!) of the input size.

